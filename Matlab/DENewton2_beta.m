function [Y, infos] = DENewton2_beta(D, w, pars)
%%
% call: [Y, infos] = ENewton2_beta(D, w, []) to use default parameters
% call: [Y, infos] = ENewton2_beta(D, w, pars) to provide some parameters
%
% This code may be slow if there are too many fixed off-diagonal distances
% Improvement: Initial stage: Gradient methods (yet to be tested!)
%
% Input: D  -- Squared predistance matrix (diag(D) =0)
%        w -- w>0, a weight vector   
% pars: -- parameters needed as input
%
% pars.b -- the right-hand side vector, containing fixed distances
% pars.I -- 
% pars.J -- D(i, j) = bij fixed distances
%           =[] if no fixed distances are present
%           when b \not = [], equations are arranged as
%           [diag(Y); Yij] = [0; b]
% pars.y -- starting point, a vector of length(D)
%           default: y = zeors(k,1); k = n+ length(b);
% pars.scalew: = max(w), scale w between 0 and 1 in w/max(w) (default)
%              = 1 (no scaling)
% pars.scaleD: = max(max(D)) in D/max(max(D)) force D in (0, 1)
%                  (default)
%                  1 (n scaling on D)
% pars.eig -- eigensolver
%             1 (for eig.m, default)
%             0 (for mexeig.m provided by defeng)
% pars.tol -- error tolerance (default: 1.0e-6)
%             it is for the diagonal constraints
% pars.tol2 -- error tolerance for off diagonal constraints
%              default: 1.0e-2;
%
% pars.printyes: = 1 print information
%                  0 no output information (default)
% pars.computingXyes: = 1 computing embedding points X stored in infos.X
%                     = 0 no computing (default)
% Output:
%      Y -- Nearest Euclidean distance matrix from D
%
%    infos
%      infos.y: the optimal Lagrange multiplier corresponding to the diagonal
%               constraints and the fixed distances
%      infos.Z: the optimal dual matrix Z satisfying the KKT condition
%               Y-D +A*(y) - Z = 0;
%               and Y is the output (trace(YZ) = 0 in theory)
%      infos.X  = Embedding coordinates generated by Y
%                 -0.5JYJ = X^TX, and X =[x1, x2, ..., xn]
%               X is computed when pars.computingXyes = 1
%      infos.lambda: positive eiegnvalues of (-0.5JYJ) (decreasing order)
%      infos.P: leading eigenvectors of (-0.5JYJ) (corresponding to lambda)
%      infos.Pold: (eigenvectors of (-J(-D+\A^*(y))J)
%      infos.lambdaold: eigenvalues of (-J(-D+\A^*(y))J) in decreasing order
%      infos.rank = Embedding_Dimension;
%      infos.Iter = k;
%      infos.feval = f_eval; number of function evaluations;
%      infos.t = time_used; total cpu used
%      infos.res = norm_b; norm of the gradient at the final iterate
%                             This is the residual one finally got.
%      infos.f = val_obj; final (primal) objective function value 
%      infos.EigenD -- Total number of eigen decompositions

%%
%  This code is designed to solve %%%%%%%%%%%%%
%   min 0.5*\| X-D \|
%   s.t. X_ij = b_ij, (i,j) \in I x J (including: X_ii=0) 
%        X is positive semidefinite on the subspace
%          \{x\in \Re^n: eTx =0 \}
% The W-weight is a vector
%%
%  Based on the algorithm  in %%%%%
%  ``A Semismooth Newton Method for 
%  the Nearest Euclidean Distance Matrix Problem'' 
%  (SIMAX 34(1), 2013, pp. 67--93)
%                By 
%             Houduo Qi                        
%   
%  First version date:     August 16, 2011
%  Last modified date:     June   26, 2012  
%  Current Version date:   March  17, 2013
%%          
% Send your comments and suggestions to    %%%%%%
%        hdqi@soton.ac.uk      %%%%%%
%
% Acknowledgment: The code makes use of CorNewton.m developed by
% Houduo Qi and Defeng Sun (NUS) for computing 
% the nearest correlation matrix 
%
%%%%% Warning: Accuracy may not be guaranteed!!!!! %%%%%%%%
%% Step 0: Preliminary check whether the problem can be solved by simpler code
%
t0   = tic;
n    = size(D, 2);

% if b = [], use DENewton.m
% read other parameter values
if ~isfield(pars, 'eig')
    pars.eig = 1;
end
if ~isfield(pars, 'tol')
    pars.tol = 1.0e-6;
end
if ~isfield(pars, 'tol2')
    pars.tol2 = 1.0e-2;
end
if ~isfield(pars, 'printyes')
    pars.printyes = 0; % no print out information
end
if ~isfield(pars, 'computingXyes')
    pars.computingXyes = 0; % no computing the embedding points X
end


if ~isfield(pars, 'positive_eig_level')
    pars.positive_eig_level = 1.0e-8; % positive eigenvalues less than 1.0e-8
                                      % are treated as zeros
end
positive_eig_level = pars.positive_eig_level;

if isfield(pars, 'b')
    b = pars.b;
    sizeb = length(b);
end

if (~isfield(pars, 'b') || sizeb == 0)
   [Y, infos] = DENewton_beta(D, w, pars); % pars are at default
   return
end

%%%%%%%%%% otherwise, b \not= []
b = pars.b;
I = pars.I;
J = pars.J;
k = n + length(b); % total number of linear constraints
maxw = max(w);

%  Check if it is the equal diagonal weight case
%
prnt      = pars.printyes;
equalweightflag = any(w/maxw - ones(n,1));
if (equalweightflag == 0)
%     if prnt
%        fprintf('\n Equal diagonal weight: call ENewton2_beta.m');
%     end
    [Y, infos] = ENewton2_beta(D, pars); % 
    infos.Z   = maxw^2*infos.Z;
    infos.y   = maxw^2*infos.y;
    infos.res = maxw*infos.res;
    infos.f   = maxw^2*infos.f;
    return
end

%%%% Unequal weight case: continue
%
if ~isfield(pars, 'y')
    pars.y = zeros(k,1);
end

y         = pars.y;
error_tol = pars.tol;
tol2      = pars.tol2;
eigsolver = pars.eig;

if prnt
  fprintf('\n ******************************************************** \n')
  fprintf( '          The Semismooth Newton-CG Method (DENewton2.m)       ')
  fprintf('\n ******************************************************** \n')
  fprintf('\n The information of this problem is as follows: \n')
  fprintf(' Dim. of    sdp      constr  = %d \n',n)
  fprintf(' Num. of equality    constr  = %d \n',k)
end

%% Step 1: Set up data 
%
% scaling
if ~isfield(pars, 'scalew')
    pars.scalew = maxw/min(100, maxw); % scale w in (0, 100]
end

if ~isfield(pars, 'scaleD')
    maxD = max(max(D));
    pars.scaleD = maxD/min(100, maxD);   %scale D between 0 and 100
end

% keep old data before scaling
Dold = D;
wold = w;
%bold = b;

% scaling the data
scalew = pars.scalew;
scaleD = pars.scaleD;
scalefactor = scalew*scaleD;

D  = D/scaleD;
b  = b/scaleD;
w  = w/scalew;
y(1:n)  = y(1:n)./wold;
y(n+1:end) = y(n+1:end)./(sqrt(wold(I)).*sqrt(wold(J)));
y  = y/scalefactor; % toscale the Lagrangian multiplier

D     = -(D+D')/2;    % make D symmetric and use (-D): change of sign
b     = -b;

error_tol  = error_tol/scalefactor;    % control the diagonal constraints

tol2       = tol2/scalefactor;     % control the off-diagonal constraints

if error_tol < 1.0e-9 % too small
    error_tol = 1.0e-7;
end

%% Step 3: Reformulate the data for Newton's method
%
% D, b
sumw  = sum(w);
sqrtw = sqrt(w);
TD = (sqrtw*sqrtw').*D; % TD = \tilde(D)
Tb = sqrtw(I).*sqrtw(J).*b;

% calculate J^w(TD)J^w
TDw  = TD*sqrtw;
sumD = sqrtw'*TDw;
JDJ  = TDw*sqrtw';
JDJ  = (JDJ + JDJ')/sumw;
JDJ  = TD - JDJ + (sumD/sumw^2)*(sqrtw*sqrtw');

% set parameters 
Iter_Whole = 100;
Iter_inner = 20;      % maximum num of Line Search in Newton method
maxit      = 300;     % maximum num of iterations in PCG
tol        = 1.0e-2;    % relative accuracy for CGs
sigma      = 1.0e-4;    % tolerance in the line search of the Newton method

k1         = 0; % Iteration counter
f_eval     = 0;
EigenD     = 0; % number of eigen decompositions
iter_cg    = 0;

prec_time  = 0;
pcg_time   = 0; 
eig_time   = 0;

% initial point
x0 = y;

Y = JDJ + JyJ(w, I, J, y, n);
Y = -(Y + Y')/2; % - J(D+\A^*y)J

%%
eig_time0 = tic;
Y = full(Y);
[P,lambda] = MYeig(Y,eigsolver); 
eig_time = eig_time + toc(eig_time0); 
EigenD   = EigenD + 1;
 
%%
[f0,Fy] = gradient2(y,I,J,lambda,P,Y,TD,Tb);
f_eval  = f_eval + 1;
f       = f0;
b       = [zeros(n,1); Tb] - Fy;
norm_b1 = norm(b(1:n));
norm_b2 = norm(b(n+1:end));
norm_b  = norm(b);
%

Omega12 = omega_mat(lambda);

val_D     = sum(sum(TD.*TD))/2;
Initial_f = val_D-f0;

if prnt
  fprintf('\n Initial Dual Objective Function value  = %d \n', Initial_f)
end
tt = toc(t0);
[hh,mm,ss] = time(tt);

if prnt
  fprintf('\n   Iter.   Num. of CGs     Step length      Norm of gradient      time_used ')
  fprintf('\n    %d         %2.0d              %3.2e                      %3.2e             %d:%d:%d ',0,str2num('-'),str2num('-'),norm_b1,hh,mm,ss)
end

while ((norm_b1 > error_tol) | (norm_b2 > tol2)) && (k1<Iter_Whole)
    
    k1 = k1 +1;

     % begin of calculating Newton direction
     t2 = tic;
     c = precond_matrix(w, I,J,Omega12,P);
     prec_time = prec_time + toc(t2);

     t3 = tic;
%       [d,flag,relres,iterk] = bicgstab(@(x) Jacobian_matrix(x, I, J, Omega12, P), ...
%          b, tol, maxit);
     [d,flag, ~,iterk] = pre_cg(w,b,I,J,tol,maxit,Omega12,P,c);
     %n_max = 200;
     %[xMR, iflag, total_iters, resMR] =
     %[d,flag,iterk, relres] = pminres(b, I, J, min(0.5, norm_b),n_max, Omega12, P, c);
     pcg_time = pcg_time + toc(t3);
     iter_cg = iter_cg + iterk;
    % end of calculating Newton direction
% if cg is unsuccessful, use alternating projection method with fixed
% steplength 1
% the alternating projection part needs to be checked!
%
    if (flag~=0); % if CG is unsuccessful, use the negative gradient direction 
      disp('..... Not a full Newton step......')
      disp('..... Use alternating projection......')
      d = b; % = b0-Fy;
      y = x0 + d;
      Y = JDJ + JyJ(w,I,J,y,n);
      Y = -(Y + Y')/2; % - J(D+\A^*y)J

%%
 eig_time0 = tic;
 [P,lambda] = MYeig(Y,eigsolver); 
 eig_time = eig_time + toc(eig_time0); 
 EigenD   = EigenD + 1;
 
%%
  [f,Fy] = gradient2(y,I,J,lambda,P,Y,TD,Tb);
     k_inner = 0;
    else % Newton's method
     slope = (Fy-[zeros(n,1); Tb])'*d; 
    %d = b; % negative gradient direction
    y = x0 + d;   
    
    Y = JDJ + JyJ(w, I,J,y,n);
    Y = -(Y + Y')/2; % - J(D+\A^*y)J

%%
 eig_time0 = tic;
 [P,lambda] = MYeig(full(Y),eigsolver); 
 eig_time = eig_time + toc(eig_time0); 
 EigenD   = EigenD + 1;
 
%%
    
    [f,Fy] = gradient2(y,I,J,lambda,P,Y,TD,Tb);
    k_inner=0;
    while( k_inner <= Iter_inner && f > f0 + sigma*0.5^k_inner*slope + 1.0e-6 )        
        k_inner = k_inner + 1;
        y = x0 + 0.5^k_inner*d;    % backtracking       
        
        Y = JDJ + JyJ(w, I,J,y,n);
        Y = -(Y + Y')/2; % - J(D+\A^*y)J

%%
 eig_time0 = tic;
 Y = full(Y);
 [P,lambda] = MYeig(Y,eigsolver); 
 eig_time = eig_time + toc(eig_time0); 
 EigenD   = EigenD + 1;
 
%%
  [f,Fy] = gradient2(y,I,J,lambda,P,Y,TD,Tb);
         
    end    % End for line search
    end % end for flag ~= 0
    f_eval = f_eval+k_inner+1;
    
    x0     = y;
    f0     = f;
    b       = [zeros(n,1); Tb] - Fy;
    norm_b1 = norm(b(1:n));
    norm_b2 = norm(b(n+1:end));
    norm_b = norm(b);
 
    Omega12 = omega_mat(lambda);
    
    tt = toc(t0);
    [hh,mm,ss] = time(tt); 
    
%     fprintf('\n   %2.0d         %2.0d               %3.2e          %3.2e             %d:%d:%d ', ...
%         k1,iterk,0.5^k_inner, Gap,hh,mm,ss)
    if prnt
      fprintf('\n   %2.0d         %2.0d               %3.2e          %3.2e             %d:%d:%d ', ...
        k1,iterk,0.5^k_inner,norm_b1,hh,mm,ss)
    end
    
%       % slow convergence test
%     if (k1 < num)
%         f_hist(k1+1) = f;
%     else
%         for i =1:num-1
%             f_hist(i) = f_hist(i+1);
%         end
%         f_hist(num) = f;
%     end
%     if (k1 >= num-1 && f_hist(1) - f_hist(num) < 1.0e-5 && norm_b > error_tol) 
%                                               % could set to 10e-07
%         fprintf('\n Progress is too slow! :(')
%         break
%     end

end   %End of while loop

% Optimal solution Y*
Ip = find(lambda>0); % could set to 1.0e-7
%In = find(lambda<0); % could set to -1.0e-7
Embedding_Dimension = sum(lambda < -positive_eig_level); % length of In
  % The eigen-decomposition is on -J(D+\A^*y)J
  % The imbedding dimension is the number of negative eigenvalues of
  % -J(D+\A^*y)J.
  % This result is based on Haydan-Wells projection formula
  % see Eq. (37) in my paper.
r = length(Ip);

Ay = sparse(I, J, y(n+1:end), n, n);
Ay = (Ay+Ay')/2 + sparse(diag(y(1:n)));

if (r==0)
    Y = TD + Ay;
elseif (r==n)
    Y = TD + Ay + Y;
elseif (r<=n/2)
    lambda1 = lambda(Ip);
    lambda1 = lambda1.^0.5;
    P1 = P(:, 1:r);
    P1 = P1*sparse(diag(lambda1));
    Y = P1*P1';
    Y = TD+Ay + Y;% Optimal solution Y* 
else 
    
    lambda2 = -lambda(r+1:n);
    lambda2 = lambda2.^0.5;
    P2 = P(:, r+1:n);
    P2 = P2*sparse(diag(lambda2));
    Y = Y + P2*P2'; 
    Y = TD+Ay + Y;% Optimal solution Y* 
end
 Y = (Y+Y')/2;
 
%% Information obtained so far (i.e., before scaling back)
% set diagonals of Y to zero
  Y(1:(n+1):end) = 0;
% dual matrix Z (dual vector y is already obtained)
  Z = -TD + Y - Ay; % -D = Dold/Sfactor
  Z = -Z; % Z = (-Y) + D + Ay % because -Y is distance matrix
% compute the comlementarity gap
% comp_gap = sum(sum(Y.*Z)); % this term should be 0 in theory
 
% computing the objective (both primal and dual) for the reformulated
% problem
dual_f = val_D - f;
primal_f = 0.5*sum(sum((( Y - TD).^2)));
%%%%%%%%% dual_f - primal_f = 0 in theory

% return Y, y, Z for the original problem on K^n_+ with Dold, wold
%
sqrtw = sqrt(wold);
w1 = 1./sqrtw;
Y = abs(Y); % put (-1) sign back to Y and abs ensure Yij >= 0

Y = scalefactor*((w1*w1').*Y);
y(1:n) = scalefactor*(wold.*y(1:n));
y(n+1:end) = scalefactor*(sqrtw(I).*sqrtw(J).*y(n+1:end));
Z = scalefactor*((sqrtw*sqrtw').*Z);

infos.y = y;
infos.Z = Z;

% the output Y, y, Z satisfies in theory
% (wold*wold').*(Y - Dold) + diag(y) - Z = 0 %dual feasibility
%  check the dual feasibility
%
Z = (wold*wold').*(Y - Dold) +  Ay - Z;
dfeasi = sum(sum(Z.*Z));
dfeasi = sqrt(dfeasi); % should be very small
infos.dfeasi = dfeasi;

norm_b  = scalefactor*norm_b;

% calculate the final objective function value
Dold = (sqrtw*sqrtw').*(Y-Dold);
val_obj = 0.5*sum(sum((Dold.^2)));
 
% More output information
%infos.Pold   = P;
%infos.lambdaold = lambda;
infos.rank   = Embedding_Dimension;
infos.Iter   = k1;
infos.feval  = f_eval;

infos.res    = norm_b;
infos.f      = val_obj;
infos.EigenD = EigenD;

%%
computingXyes = pars.computingXyes;
% Embedding coordinates generated by the calculated nearest EDM: Y
% - 0.5JYJ = 0.5 * Sfactor * \Pi_{\S^n_+} (J(-D + \A^*(y))J) = X^TX
%
% There are two ways to comput X

%%%%%%%%%% 1st way: to use exisiting eigeninformation %%%%%%%%%%
% It is those negative eigenvalues in lambda that gives X^TX
% Comment: the resulting distance matrix from X may be less
%          accurate than that obtained by the 2nd way
%          This is because Y may not be a true EDM due to the less
%          accuracy on off-diagonal constraints.
% verify: diff = squareform(pdist(X')) - Y
%         normdiff = norm(diff, 'fro');
%         this may be in the order of 1.0e-3
% 
% if computingXyes
%    lambda = abs(lambda); % lambda has been mulitplied by Sfactor
%    lambda = lambda(end:-1:1);
%    P = P(:, end:-1:1);
%    lambda = 0.5*lambda(1:Embedding_Dimension); % positive eigenvalues in -0.5JYJ
%    P = P(:, 1:Embedding_Dimension);
%    infos.P = P;
% 
%    P = P*diag(lambda.^(0.5));
%    P = P';
%
%    infos.lambda = lambda;
%    infos.X = P;
% end
%
%%%%%%%%%%%%%% end of 1st way

%%%%%%%%%%%%%%% 2nd way: direct decompsoition of -0.5JYJ %%%%%%%%%%%%%
% Comment: the resulting distance matrix from X is more
%          accurate than that obtained by the 1st way
% verify: diff = squareform(pdist(X')) - Y
%         normdiff = norm(diff, 'fro');
%         this is in the order of 1.0e-5

if computingXyes
   z = sum(Y, 2);
   sumY = sum(z);
   Z = z*ones(1,n);
   Z = Y - (Z+Z')/n + sumY/n^2;
   Z = -0.25*(Z+Z'); % 0.25 is used because 0.5 for symmetry 
                     % and 0.5 for -0.5JYJ

   eig_time0 = tic;
   [P,lambda] = MYeig(Z,eigsolver); 
   eig_time = eig_time + toc(eig_time0); 
   EigenD   = EigenD + 1;
   infos.P = P;
   infos.lambda = lambda;
   
   r = sum(lambda > positive_eig_level);
   Embedding_Dimension = r;
   P = P(:, 1:r);
   lambda = lambda(1:r).^(1/2);
   P = P*sparse(diag(lambda));

   infos.X = P';
   infos.EigD = EigenD;
   infos.rank = Embedding_Dimension;
end
%%%%%%%%%%%%%%%%%% End of 2nd way %%%%%%%%%%%%%%%%%%%%%%

time_used = toc(t0);
infos.t      = time_used;

% print out information
if prnt
fprintf('\n')
fprintf('\n ================ Final Information ================= \n');
fprintf(' Total number of iterations      = %2.0f \n',k1);
fprintf(' Norm of Gradient                = %3.2e \n', full(norm_b))
fprintf(' Number of func. evaluations     = %2.0f \n',f_eval)
fprintf(' Number of CG Iterations         = %2.0f \n',iter_cg)
fprintf(' Objective value for the Dual Problem =========== %d \n', full(dual_f))
fprintf(' Objective value for the Primal Problem ========= %d \n', full(primal_f))
% for the solved dual problem
fprintf(' Final objective value for the Original Problem = %d \n', full(val_obj))
fprintf(' Computing time for preconditioner     = %3.1f \n',prec_time)
fprintf(' Computing time for CG iterations      = %3.1f \n',pcg_time)
fprintf(' Computing time for eigen-decom        = %3.1f \n',eig_time)
fprintf(' Embedding dimension ================= %d \n',Embedding_Dimension)
fprintf(' Total computing time (in s) ==== =====================%d \n',time_used)
fprintf(' ====================================================== \n');
end
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  End of the main program   %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%  **************************************
%%  ******** All Sub-routines  ***********
%%  **************************************

%%% To change the format of time 
function [h,m,s] = time(t)
t = round(t); 
h = floor(t/3600);
m = floor(rem(t,3600)/60);
s = rem(rem(t,60),60);
return
%%% End of time.m

function X = JyJ(w, I, J, y, n)

X = sparse(I, J, y((n+1):end), n, n) + sparse(diag(y(1:n)));
%%
X    = (X+X')/2; % X = \A^*y
sumw = sum(w);
w    = sqrt(w);
Xw   = (X*w)/sumw;
X    = X - (Xw*w' + w*Xw') + (w'*Xw)/sumw*(w*w');

return
%End of JyJ.m

%%% mexeig decomposition
function [P,lambda] = MYeig(X,eigsolver)
if eigsolver %% use matlab built-in function eig
     [P, Lambda] =  eig(X);   %% X= P*diag(D)*P'
     P = real(P);
     lambda = real(diag(Lambda));
    
else %% use mexeig developed by Prof. Defeng Sun
    [P,lambda] = mexeig(X);
    P          = real(P);
    lambda     = real(lambda);    
    
end

%% make sure eigenvalues are in decreasing order
if issorted(lambda)
    lambda = lambda(end:-1:1);
    P      = P(:,end:-1:1);
elseif issorted(lambda(end:-1:1))
    return;
else
    [lambda, Inx] = sort(lambda,'descend');
    P = P(:,Inx);
end
return
%%% End of MYeig.m

function [f, Fy] = gradient2(y, I, J, lambda, P, Y, D, b)
%
% f: Dual objective function value
% Fy: Gradient of the dual function
% fp: Primal objective function value
%
% Dy = D + \A^*y
% Y = -J(D+\A^*y)J
% [P, Lambda] = eigmex(Y)
%
n = length(lambda);
y1 = y(1:n);
y2 = y((n+1):end);
Y2 = sparse(I, J, y2, n, n);
Y2 = 0.5*(Y2+Y2') + diag(y1);
Y2 = D + Y2; % D+\A^*(y)
Y2 = Y2 + Y; % (Y-JYJ), where Y = Y2
%
lambda = -lambda;
lambda = lambda(n:-1:1);
P = P(:, n:-1:1);
r = sum(lambda > eps.^(3/4));
lambda1 = lambda(1:r);
%
f = 0.5*sum(lambda1.^2) + 0.5*sum(sum(Y2.*Y2)) - b'*y2;
%
lambda1 = lambda1.^(0.5);
P1 = P(:, 1:r)*diag(lambda1);

%%%%%% 1st way to calculate Fy
n0 = length(I);
k  = n+n0;
Fy = zeros(k,1);

i = 1;
while (i <= n)
    Fy(i) = sum(P1(i, :).^2);
    i = i+1;
end
Fy(1:n) = Fy(1:n) + diag(Y2);

i = 1;
while (i <= n0)
    Fy(n+i) = P1(I(i), :)*P1(J(i), :)' + Y2(I(i), J(i));
    i = i+1;
end
%%%%%% End of 1st way

% %%%%%% 2nd way to calculate Fy
% Y2  = P1*P1' + Y2;
% idx = sub2ind([n,n], I, J); %linear indexing: =(J-1)*n + I
% Fy = Y2(idx); 
% Fy  = [diag(Y2); Fy]; % gradient should be Fy - [0; b]
                      % we do it in the main program 
%%%%%% End of 2nd way

return
%%% End of gradient.m

%%% To generate the essential part of the first-order difference of d
function Omega12 = omega_mat(lambda)
% We compute omega only for 1<=|idx|<=n-1
n       = length(lambda);
idx.idp = find(lambda>0);
idx.idm = setdiff([1:n],idx.idp);
r       = length(idx.idp);

if ~isempty(idx.idp)
    if (r == n)
        Omega12 = ones(n,n);
    else
        s  = n-r;
        dp = lambda(1:r);
        dn = lambda(r+1:n);
        
        Omega12 = (dp*ones(1,s))./(abs(dp)*ones(1,s) + ones(r,1)*abs(dn'));
        %Omega12 = max(1e-15,Omega12);
        %Omega = [ones(r) Omega12; Omega12' zeros(s)];
    end
else
    Omega12 = [];
end
return
%%% End of omega_mat.m 

%%% To generate the Jacobian product with x: F'(y)(x)
function Ax = Jacobian_matrix(w,x,I,J,Omega12,P)
n      = length(P);
n0     = length(I);
k      = n+n0;
if (k ~= length(x))
    disp('Error: Dimensions do not add up!')
end
[r,s]  = size(Omega12); 

tau = 1.0e-10;

Ax = zeros(k,1);
%%
%
Z = sparse(I, J, x(n+1:end), n, n) + sparse(diag(x(1:n)));
Z = 0.5*(Z+Z'); % \A^*(x)
    
sumw = sum(w); % = t in DE2Newton
sqrtw = sqrt(w);
xw   = Z*sqrtw; %old startx
sumxw = sqrtw'*xw;
%%
%
if (r==0)
    Ax(1:n) = (1+tau)*x(1:n);
    Ax(n+1:end) = (0.5+tau)*x(n+1:end); 
    return
end
%%
%
if (r==n)
    Ax(1:n) = (2/sumw)*(xw.*sqrtw) - (sumxw/sumw^2)*w;
    Ax(n+1:end) = (1/sumw)*(xw(I, :).*sqrtw(J, :) + sqrtw(I, :).*xw(J,:)) ...
                - (sumxw/sumw^2)*(sqrtw(I, :).*sqrtw(J, :));
    Ax = Ax + tau*x;
    return
end
%%
    
    P1 = P(:,1:r);
    P2 = P(:,r+1:n);
        
    pbar = (P'*sqrtw)/sumw; % p_w
    startx = P'*xw; % p_x
    startx = 0.5*sumxw*pbar - startx;
    PI = P'.*pbar(:, ones(n,1)); %Py
    PJ = P'.*startx(:, ones(n,1)); %Px
        
    const_sparse = 5;  % min(5,n/50); 
    if (k<=const_sparse*n)
        % sparse form
        if (r<n/2)
            %H = (Omega.*(P'*sparse(Z)*P))*P';
            H1 = P1'*sparse(Z);
            Omega12_old = Omega12;
            Omega12 = Omega12.*(H1*P2);
            H = [(H1*P1)*P1' + Omega12*P2'; Omega12'*P1'];
           
            PI12 = PI(1:r, :)'*Omega12_old;
            PJ12 = Omega12_old'*PJ(1:r, :);
            
            for i=1:n
                Ax(i) = x(i) - P(i,:)*H(:,i);
                v  = sum(PI(1:r, i))*sum(PJ(1:r, i)) ...
                   + PI12(i, :)*PJ(r+1:n, i) + PI(r+1:n, i)'*PJ12(:, i);                 
                Ax(i) = Ax(i) - 2*v;
            end
             
            for i=1:n0
               Ax(n+i) = 0.5*x(n+i) - P(I(i),:)*H(:,J(i));
               
               v  = sum(PI(1:r, I(i)))*sum(PJ(1:r, J(i))) ...
                  + PI12(I(i), :)*PJ(r+1:n, J(i))  ...
                  + PI(r+1:n, I(i))'*PJ12(:, J(i));
                 
                Ax(n+i) = Ax(n+i) - v;  
                
               v = sum(PJ(1:r, I(i)))*sum(PI(1:r, J(i))) ...
                 + PJ12(:, I(i))'*PI(r+1:n, J(i)) ...
                 + PJ(r+1:n, I(i))'*PI12(J(i), :)';
                 
               Ax(n+i) = Ax(n+i) - v;                    
                  
            end
        else % if r>=n/2, use a complementary formula.
            %H = ((E-Omega).*(P'*Z*P))*P';               
            H2 = P2'*sparse(Z);
            Omega12 = ones(r,s)- Omega12;
            Omega12_old = Omega12;
            Omega12 = Omega12.*((H2*P1)');
            H = [Omega12*P2'; Omega12'*P1' + (H2*P2)*P2'];
            
            PI12 = PI(r+1:n, :)'*Omega12_old';
            PJ12 = Omega12_old*PJ(r+1:n, :);
            
                 %%
            % the case r==n + (\A(H))
            Ax(1:n) = (2/sumw)*(xw.*sqrtw) - (sumxw/sumw^2)*w;
    Ax(n+1:end) = (1/sumw)*(xw(I, :).*sqrtw(J, :) + sqrtw(I, :).*xw(J,:)) ...
                - (sumxw/sumw^2)*(sqrtw(I, :).*sqrtw(J, :));
            for i=1:n
               Ax(i) = Ax(i) + P(i,:)*H(:,i);
               
               v  = sum(PI(r+1:n, i))*sum(PJ(r+1:n, i)) ...
                   + PI12(i, :)*PJ(1:r, i) + PI(1:r, i)'*PJ12(:, i);
               
               Ax(i) = Ax(i) + 2*v;
            end
            for i=1:n0
               Ax(n+i) = Ax(n+i) + P(I(i),:)*H(:,J(i)); 
               
               v  = sum(PI(r+1:n, I(i)))*sum(PJ(r+1:n, J(i))) ...
                  + PI12(I(i), :)*PJ(1:r, J(i)) ...
                  + PI(1:r, I(i))'*PJ12(:, J(i));
               
               Ax(n+i) = Ax(n+i) + v;
                   %
               v  = sum(PJ(r+1:n, I(i)))*sum(PI(r+1:n, J(i))) ...
                  + PJ12(:, I(i))'*PI(1:r, J(i)) ...
                  + PJ(1:r, I(i))'*PI12(J(i), :)';
                   %                  
                Ax(n+i) = Ax(n+i) + v;
            end
        end
     else %dense form k > const_sparse*n
        %Z = full(Z); to use the full form
        % dense form
        if (r<n/2) 
            %H = P*(Omega.*(P'*Z*P))*P';            
            H1 = P1'*Z;
            Omega12_old = Omega12;
            Omega12 = Omega12.*(H1*P2);            
            H = P1*((H1*P1)*P1'+ 2.0*Omega12*P2');            
            H = (H + H')/2; 
            
            PI12 = PI(1:r, :)'*Omega_old;
            PJ12 = Omega12_old'*PJ(1:r, :);
            
            for i = 1:n
                Ax(i) = x(i) -  H(i,i);
                v  = sum(PI(1:r, i))*sum(PJ(1:r, i)) ...
                   + PI12(i, :)*PJ(r+1:n, i) + PI(r+1:n, i)'*PJ12(:, i);                 
                Ax(i) = Ax(i) - 2*v;
            end
            
            for i=1:n0
                Ax(n+i) = 0.5*x(n+i) -  H(I(i),J(i));
                
                v  = sum(PI(1:r, I(i)))*sum(PJ(1:r, J(i))) ...
                   + PI12(I(i), :)*PJ(r+1:n, J(i)) ...
                   + PI(r+1:n, I(i))'*PJ12(:, J(i));
                 
                Ax(n+i) = Ax(n+i) - v; 
                
                v = sum(PJ(1:r, I(i)))*sum(PI(1:r, J(i))) ...
                  + PJ12(:, I(i))'*PI(r+1:n, J(i)) ...
                  + PJ(r+1:n, I(i))'*PI12(J(i), :)';
                 
               Ax(n+i) = Ax(n+i) - v;                    
                  
            end   
        else % if r>=n/2, use a complementary formula.
            %H = - P*( (E-Omega).*(P'*Z*P) )*P';           
            H2 = P2'*Z;
            Omega12 = ones(r,s)-Omega12;
            Omega12_old = Omega12;
            Omega12 = Omega12.*(H2*P1)';
            H = P2*( 2.0*(Omega12'*P1') + (H2*P2)*P2');            
            H = (H + H')/2;
            
            PI12 = PI(r+1:n, :)'*Omega12_old';
            PJ12 = Omega12_old*PJ(r+1:n, :);
            %%
            % the case r==n + (\A(H))
            Ax(1:n) = (2/sumw)*(xw.*sqrtw) - (sumxw/sumw^2)*w;
    Ax(n+1:end) = (1/sumw)*(xw(I, :).*sqrtw(J, :) + sqrtw(I, :).*xw(J,:)) ...
                - (sumxw/sumw^2)*(sqrtw(I, :).*sqrtw(J, :));
             
             for i=1:n
                Ax(i) = Ax(i) + H(i,i); %from diagonal part
                v  = sum(PI(r+1:n, i))*sum(PJ(r+1:n, i)) ...
                   + PI12(i, :)*PJ(1:r, i) + PI(1:r, i)'*PJ12(:, i);
               
               Ax(i) = Ax(i) + 2*v;
             end
             
             for i=1:n0
                Ax(n+i) = Ax(n+i) + H(I(i),J(i)); %from diagonal part
                
                v  = sum(PI(r+1:n, I(i)))*sum(PJ(r+1:n, J(i))) ...
                  + PI12(I(i), :)*PJ(1:r, J(i)) ...
                  + PI(1:r, I(i))'*PJ12(:, J(i));
               
               Ax(n+i) = Ax(n+i) + v;
                   %
               v  = sum(PJ(r+1:n, I(i)))*sum(PI(r+1:n, J(i))) ...
                  + PJ12(:, I(i))'*PI(1:r, J(i)) ...
                  + PJ(1:r, I(i))'*PI12(J(i), :)';
                   %                  
                Ax(n+i) = Ax(n+i) + v;
             end
             
        end
    end
 Ax = Ax + tau*x;

return
%%% End of Jacobian_matrix.m  

%%% To generate the (approximate) diagonal preconditioner
function c = precond_matrix(w, I,J,Omega12,P) 
%
n     = size(P, 2);
n0    = length(I); % number of extra fixed distance constraints
k     = n0 + n;
[r, ~] = size(Omega12);

c = ones(k,1);
sqrtw = sqrt(w);
sumw  = sum(w);
tau = 1.0e-8;

if (r==0) % Omega = 0
    c(1:n) = 1;
    c((n+1):end) = 0.5;
    c = max(tau, c);
    return
end
%
if (r==n) % Omega = E
    t = w./sumw;
    c(1:n) = 2*t - t.^2;
    wIJ = w(I,:).*w(J,:);
    c(n+1:end) = (2/sumw)*sqrt(wIJ) - (0.5/sumw^2)*(w(I,:)+w(J,:)).*sqrt(wIJ);
    c = max(tau, c);
    return
end
%% otherwise, 0<r<n
%const_prec = 2; % normally choose 2 and set this to n/2 to use accurate c
H0 = P';  
pw = H0*sqrtw/sumw; %average row sum
H1 = H0- pw*sqrtw';
H = H0.*H1; % P'o(P' - pw*sqrtw')
H2 = H0(:, I).*H1(:, J);
H3 = H0(:, J).*H1(:, I); %size n x n0
                                
%
if r < n/2
   H12 = H(1:r,:)'*Omega12;
   for i=1:n
       c(i) = (sum(H(1:r,i))).^2;
       c(i) = c(i) + 2.0*(H12(i,:)*H(r+1:n,i));
       c(i) = 1 - c(i);
   end
   % calculate the remaining diagonal elements
   H22 = H2(1:r, :)'*Omega12;
   H23 = Omega12'*H3(1:r, :);
   for i=1:n0
       c(n+i) = sum(H(1:r, I(i)))*sum(H(1:r, J(i))) ...
             + H12(I(i),:)*H(r+1:n, J(i)) + H12(J(i),:)*H(r+1:n, I(i));
       c(n+i) = c(n+i) + sum(H2(1:r, i))*sum(H3(1:r, i)) ...
             + H22(i,:)*H3(r+1:n, i) + H2(r+1:n,i)'*H23(:, i);
       c(n+i) = 0.5 - 0.5*c(n+i);
   end
   
else % r>=n/2, use a complementary formula
    Omega12 = 1 - Omega12;
    H12 = Omega12*H(r+1:n,:);
    for i=1:n
        c(i) = (sum(H(r+1:n,i)))^2;
        c(i) = c(i) + 2.0*(H(1:r,i)'*H12(:,i));
    end
    t = w./sumw;
    c(1:n) = 2*t - t.^2;
    % calculate the remaining diagonal elements
   H22 = Omega12 * H2(r+1:n, :);
   H22 = H22';
   H23 = Omega12*H3(r+1:n, :);
   for i=1:n0
       c(n+i) = sum(H(r+1:n, I(i)))*sum(H(r+1:n, J(i))) ...
             + H(1:r, I(i))'*H12(:, J(i)) + H12(:,I(i))'*H(1:r, J(i));
       c(n+i) = c(n+i) + sum(H2(r+1:n, i))*sum(H3(r+1:n, i)) ...
             + H22(i,:)*H3(1:r, i) + H2(1:r,i)'*H23(:, i);
       c(n+i) = 0.5*c(n+i);
   end
   wIJ = w(I,:).*w(J,:);
   c(n+1:end) = c(n+1:end) + ...
       (2/sumw)*sqrt(wIJ) - (0.5/sumw^2)*(w(I,:)+w(J,:)).*sqrt(wIJ);
end
c = max(tau, c);

return
%%% End of precond_matrix.m 

%%%%%%%%%%%%%%%%%%%%%%% PCG method  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% This is exactly the algorithm given by Hestenes and Stiefel (1952)
%%% An iterative method to solve A(x)=b  
%%% The symmetric positive definite matrix M is a preconditioner for A.
%%% See Pages 527 and 534 of Golub and va Loan (1996)
function [p,flag,relres,iterk] = pre_cg(w,b,I,J,tol,maxit,Omega12,P,c)
n      =size(P, 2);
k1     = length(c);
flag   = 1;
iterk  = 0;
relres = 1000; % give a big value on relres

r    = b;           % initial x0=0 
n2b  = norm(b);     % norm of b
tolb  = max(tol,min(0.1,n2b))*n2b;       % relative tolerance tol*n2b;   % relative tolerance 

if n2b > 1.0e2
    maxit = min(10,maxit); % In Defeng's implementation: min(1, maxit);
end
p = zeros(k1,1);

%%% preconditioning
z   = r./c;  % z = M\r; here M =diag(c); if M is not the identity matrix 
rz1 = r'*z; 
rz2 = 1; 
d   = z;

%%% CG iteration
for k=1:maxit
   if (k>1)
       beta = rz1/rz2;
       d    = z + beta*d;
   end
   
   ww = Jacobian_matrix(w,d,I,J,Omega12,P);
   %w = Jacobian_matrix(d,I,J,Omega12,P); % W =A(d)
   
%   if k1 > n  %% if there are more constraints than n
%      ww = ww + 1.0e-2*min(1.0, 0.1*n2b)*d;  %% perturb it to avoid numerical singularity
%   end
   denom  = d'*ww;
   iterk  = k;
   relres = norm(r)/n2b;        %relative residue=norm(r)/norm(b)
   
   if denom <= 0 
       p = d/norm(d); % d is not a descent direction
       break;   % exit
   else
       alpha = rz1/denom;
       p     = p + alpha*d;
       r     = r - alpha*ww;
   end
   
   z = r./c; %  z = M\r; here M =diag(c); if M is not the identity matrix   
   if (norm(r) <= tolb)   % Exit if Hp=b solved within the relative tolerance
       iterk  = k;
       relres = norm(r)/n2b;          %relative residue =norm(r)/norm(b)
       flag   = 0;
       break;
   end
   rz2 = rz1;
   rz1 = r'*z;
end
return
%%% End of pre_cg.m
 